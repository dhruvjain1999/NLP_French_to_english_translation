{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd9aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://notebook.community/angelmtenor/data-science-keras/machine_translation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81a9e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the library \n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "import time\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import requests\n",
    "import glob\n",
    "import helper\n",
    "import numpy as np\n",
    "import project_tests as tests\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "from pickle import load\n",
    "from pickle import dump\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree,export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors, metrics,datasets,svm,linear_model, tree, ensemble\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.datasets import make_classification,load_iris,load_digits\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score,ParameterGrid,GridSearchCV,train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer,HashingVectorizer, CountVectorizer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression,Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV,train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,Normalizer,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats.mstats import gmean\n",
    "\n",
    "from numpy import mean,std\n",
    "from matplotlib.colors import ListedColormap\n",
    "from datetime import datetime\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "sns.set()\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "plt.style.use('fivethirtyeight')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import helper\n",
    "import keras\n",
    "# helper.info_gpu()\n",
    "np.random.seed(9)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8c0add2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'helper' from 'C:\\\\Users\\\\Dhruv Jain\\\\Desktop\\\\Csc_641\\\\Project_Machine_Translation\\\\helper.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(helper)\n",
    "\n",
    "# helper.info_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8f5b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/udacity/deep-learning-v2-pytorch/3bd7dea850e936d8cb44adda8200e4e2b5d627e3/intro-to-pytorch/helper.py\n",
    "    \n",
    "# import importlib\n",
    "# importlib.reload(helper)\n",
    "# !pip install wget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63c67b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load dataset\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data.split('\\n')\n",
    "\n",
    "\n",
    "with open('small_vocab_en', \"r\") as f:\n",
    "    english_sentences = f.read().split('\\n')\n",
    "with open('small_vocab_fr', \"r\") as f:\n",
    "    french_sentences = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564ab7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 137861\n",
      "\n",
      "sample 0:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .  \n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril . \n",
      "\n",
      "sample 1:\n",
      "the united states is usually chilly during july , and it is usually freezing in november .  \n",
      "les Ã©tats-unis est gÃ©nÃ©ralement froid en juillet , et il gÃ¨le habituellement en novembre . \n",
      "\n",
      "sample 2:\n",
      "california is usually quiet during march , and it is usually hot in june .  \n",
      "california est gÃ©nÃ©ralement calme en mars , et il est gÃ©nÃ©ralement chaud en juin . \n",
      "\n",
      "sample 3:\n",
      "the united states is sometimes mild during june , and it is cold in september .  \n",
      "les Ã©tats-unis est parfois lÃ©gÃ¨re en juin , et il fait froid en septembre . \n",
      "\n",
      "sample 4:\n",
      "your least liked fruit is the grape , but my least liked is the apple .  \n",
      "votre moins aimÃ© fruit est le raisin , mais mon moins aimÃ© est la pomme . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sentences: {}\\n\".format(len(english_sentences)))\n",
    "for i in range(5):\n",
    "    print(\"sample {}:\".format(i))\n",
    "    print(\"{}  \\n{} \\n\".format(english_sentences[i], french_sentences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fcb754b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: 1823250 words, 227 unique words\n",
      "French: 1961295 words, 355 unique words\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "words = dict()\n",
    "words[\"English\"] = [word for sentence in english_sentences for word in sentence.split()]\n",
    "words[\"French\"] = [word for sentence in french_sentences for word in sentence.split()]\n",
    "\n",
    "for key, value in words.items():\n",
    "    print(\"{}: {} words, {} unique words\".format(key,\n",
    "                                                 len(value), len(collections.Counter(value))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "24ec8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [4]:\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(x)\n",
    "    tokens = tokenizer.texts_to_sequences(x)\n",
    "\n",
    "    return tokens, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d09209de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [5]:\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to. If None, longest sequence length in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    return pad_sequences(x, maxlen=length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "06ea968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n"
     ]
    }
   ],
   "source": [
    "# In [6]:\n",
    "def preprocess(x, y, length=None):\n",
    "    \"\"\"\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x, length)\n",
    "    preprocess_y = pad(preprocess_y, length)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dims\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "\n",
    "x, y, x_tk, y_tk = preprocess(english_sentences, french_sentences)\n",
    "print('Data Preprocessed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "379e3ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [7]:\n",
    "# Only the 10 last translations will be predicted\n",
    "x_train, y_train = x[:-10], y[:-10]\n",
    "x_test, y_test = x[-10:-1], y[-10:-1]  # last sentence removed\n",
    "test_english_sentences, test_french_sentences = english_sentences[-10:], french_sentences[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c13b665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In [8]:\n",
    "def logits_to_text(logits, tokenizer, show_pad=True):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>' if show_pad else ''\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0704321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 15, 19)            3781      \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 42)               5292      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               5504      \n",
      "                                                                 \n",
      " repeat_vector_3 (RepeatVect  (None, 21, 128)          0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 21, 256)          198144    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, 21, 345)          88665     \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301,386\n",
      "Trainable params: 301,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# In [9]:\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dense, TimeDistributed, LSTM, Bidirectional, RepeatVector\n",
    "# from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dropout\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "\n",
    "def rnn_model(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build a model with embedding, encoder-decoder, and bidirectional RNN\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    vector_size = english_vocab_size // 10\n",
    "\n",
    "    model.add(\n",
    "        Embedding(\n",
    "            english_vocab_size, vector_size, input_shape=input_shape[1:], mask_zero=False))\n",
    "    model.add(Bidirectional(GRU(output_sequence_length)))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(french_vocab_size, activation=\"softmax\")))\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(\n",
    "        loss=sparse_categorical_crossentropy,\n",
    "        optimizer=optimizers.Adam(learning_rate),\n",
    "#         optimizer=keras.optimizers.adam(learning_rate),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = rnn_model(x_train.shape, y_train.shape[1], len(x_tk.word_index), len(y_tk.word_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dad9ad3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_6/embedding_6/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Dhruv Jain\\AppData\\Local\\Temp\\ipykernel_5488\\1566322911.py\", line 4, in <module>\n      get_ipython().run_line_magic('time', 'history = model.fit(x_train, y_train, batch_size=10, epochs=5, verbose=0,                            validation_split=0.2, callbacks=callbacks)')\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2369, in run_line_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1318, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 1, in <module>\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_6/embedding_6/embedding_lookup'\nindices[6,0] = 199 is not in [0, 199)\n\t [[{{node sequential_6/embedding_6/embedding_lookup}}]] [Op:__inference_train_function_101327]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_6/embedding_6/embedding_lookup' defined at (most recent call last):\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n      handle._run()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3016, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3221, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3400, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Dhruv Jain\\AppData\\Local\\Temp\\ipykernel_5488\\1566322911.py\", line 4, in <module>\n      get_ipython().run_line_magic('time', 'history = model.fit(x_train, y_train, batch_size=10, epochs=5, verbose=0,                            validation_split=0.2, callbacks=callbacks)')\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2369, in run_line_magic\n      result = fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1318, in time\n      exec(code, glob, local_ns)\n    File \"<timed exec>\", line 1, in <module>\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\embedding.py\", line 272, in call\n      out = tf.nn.embedding_lookup(self.embeddings, inputs)\nNode: 'sequential_6/embedding_6/embedding_lookup'\nindices[6,0] = 199 is not in [0, 199)\n\t [[{{node sequential_6/embedding_6/embedding_lookup}}]] [Op:__inference_train_function_101327]"
     ]
    }
   ],
   "source": [
    "# In [10]:\n",
    "print('Training...')\n",
    "callbacks = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "model.fit(x_train, y_train, batch_size=10, epochs=5, verbose=0, \\\n",
    "                          validation_split=0.2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c50f62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.75\n",
      "\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Sample: california is never nice during october , and it is sometimes rainy in autumn .\n",
      "Actual: californie est jamais agrÃ©able en octobre , et il est parfois pluvieux Ã  l' automne .\n",
      "Predicted: californie est jamais calme en printemps et il est parfois parfois ã  l' automne       \n",
      "\n",
      "Sample: our least liked fruit is the apple , but my least liked is the grape .\n",
      "Actual: notre moins aimÃ© fruit est la pomme , mais mon moins aimÃ© est le raisin .\n",
      "Predicted: votre fruits moins moins aimã© la la mais mon moins aimã© est est pãªche       \n",
      "\n",
      "Sample: we plan to visit china in march .\n",
      "Actual: nous prÃ©voyons une visite en chine en mars .\n",
      "Predicted: nous prã©voyons de visiter californie ã©tats californie prochain prochain            \n",
      "\n",
      "Sample: india is sometimes snowy during september , but it is never warm in winter .\n",
      "Actual: l' inde est parfois enneigÃ©e en septembre , mais il est jamais chaud en hiver .\n",
      "Predicted: l' inde est parfois froid en septembre mais il est jamais occupã© en novembre       \n",
      "\n",
      "Sample: france is never busy during march , and it is sometimes pleasant in september .\n",
      "Actual: la france est jamais occupÃ©e en mars , et il est parfois agrÃ©able en septembre .\n",
      "Predicted: la france est jamais calme en mars et il est parfois en en novembre       \n",
      "\n",
      "Sample: india is sometimes beautiful during spring , and it is snowy in june .\n",
      "Actual: l' inde est parfois belle au printemps , et il est neigeux en juin .\n",
      "Predicted: l' inde est parfois agrã©able en printemps et il est parfois en en        \n",
      "\n",
      "Sample: india is never wet during summer , but it is sometimes chilly in winter .\n",
      "Actual: l' inde est jamais mouillÃ© pendant l' Ã©tÃ© , mais il est parfois froid en hiver .\n",
      "Predicted: l' inde est parfois calme pendant l' hiver il il est gã©nã©ralement en en       \n",
      "\n",
      "Sample: france is never chilly during january , but it is never mild in october .\n",
      "Actual: la france est jamais froid en janvier , mais il est jamais doux en octobre .\n",
      "Predicted: l' inde est jamais tranquille en dã©cembre mais il est jamais en en        \n",
      "\n",
      "Sample: the orange is her favorite fruit , but the banana is your favorite .\n",
      "Actual: l'orange est son fruit prÃ©fÃ©rÃ© , mais la banane est votre favori .\n",
      "Predicted: l'orange est votre fruit mais mais la              \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test Accuracy: {:.2f}\\n\".format(score[1]))\n",
    "\n",
    "y = model.predict(x_test)\n",
    "\n",
    "for idx, value in enumerate(y):\n",
    "    print('Sample: {}'.format(test_english_sentences[idx]))\n",
    "    print('Actual: {}'.format(test_french_sentences[idx]))\n",
    "    print('Predicted: {}\\n'.format(logits_to_text(value, y_tk, show_pad=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016ee42f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5231be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58daebc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900efc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204eabb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1899d140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0599fe77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b9b40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13209bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd237f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5accef18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371b5b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a7f8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713da9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905c400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea89a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d60b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c08f69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "124e3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_sentences = load_data(\"small_vocab_en\")\n",
    "french_sentences =  load_data(\"small_vocab_fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ce3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open In Colab\n",
    "\n",
    "# import the libraries\n",
    "import collections\n",
    "import re\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "# from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import LSTM, GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import string\n",
    "import requests\n",
    "from keras.utils import pad_sequences\n",
    "import unicodedata\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f925f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(english_sentences)):\n",
    "    english_sentences[i] = english_sentences[i].lower()\n",
    "    \n",
    "    french_sentences[i] = french_sentences[i].lower()\n",
    "\n",
    "    english_sentences[i] = regex.sub(r'[^\\x00-\\x7f]', r'', english_sentences[i])\n",
    "    french_sentences[i] = regex.sub(r'[^\\x00-\\x7f]', r'', french_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c0b0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# empty lists\n",
    "eng_l = []\n",
    "frn_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in english_sentences:\n",
    "    eng_l.append(len(i))\n",
    "\n",
    "for i in french_sentences:\n",
    "    frn_l.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "020a6d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(frn_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d58d3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max(eng_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3f7cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'frn':frn_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c67c4545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3536f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 110\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(max(eng_l), max(frn_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf2f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba7b22ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(english_sentences)\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 100\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db3df295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French Vocabulary Size: 340\n"
     ]
    }
   ],
   "source": [
    "# prepare French tokenizer\n",
    "frn_tokenizer = tokenization(french_sentences)\n",
    "frn_vocab_size = len(frn_tokenizer.word_index) + 1\n",
    "\n",
    "frn_length = 111\n",
    "print('French Vocabulary Size: %d' % frn_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbdf4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6529911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136482"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "frn_train, frn_test1, eng_train, eng_test1 = train_test_split(french_sentences,english_sentences, test_size=0.01, random_state = 12)\n",
    "\n",
    "len(frn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f122e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(frn_test1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb4d94c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136482"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b43fd0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eng_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3ba8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare training data\n",
    "frn_train = encode_sequences(frn_tokenizer, frn_length, frn_train)\n",
    "eng_train = encode_sequences(eng_tokenizer, eng_length, eng_train)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5002462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# prepare validation data\n",
    "frn_test = encode_sequences(frn_tokenizer, frn_length, frn_test1)\n",
    "eng_test = encode_sequences(eng_tokenizer, eng_length, eng_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44e59ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "#     model.add(Bidirectional(LSTM(units, return_sequences=True)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Bidirectional(LSTM(units)))\n",
    "#     model.add(RepeatVector(out_timesteps))\n",
    "#     model.add(Bidirectional(LSTM(units, return_sequences=True)))\n",
    "#     model.add(Dropout(0.2))\n",
    "#     model.add(Dense(out_vocab, activation='softmax'))\n",
    "\n",
    "#     return model\n",
    "\n",
    "\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(Bidirectional(LSTM(units)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "933f8d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = build_model(frn_vocab_size, eng_vocab_size, frn_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "840998cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 111, 512)          174080    \n",
      "                                                                 \n",
      " bidirectional_5 (Bidirectio  (None, 1024)             4198400   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               205000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,577,480\n",
      "Trainable params: 4,577,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7c87d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136482, 111)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frn_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0142c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136482, 100)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733e707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd37f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f6a59057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = ''\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0416f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ecea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fceeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d90d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52714030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23aef5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0d2dc14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "small_vocab_fr Line 1:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "small_vocab_en Line 2:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "small_vocab_fr Line 2:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "small_vocab_en Line 3:  california is usually quiet during march , and it is usually hot in june .\n",
      "small_vocab_fr Line 3:  california est généralement calme en mars , et il est généralement chaud en juin .\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(3):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_fr Line {}:  {}'.format(sample_i + 1, french_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524313a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1823250 English words.\n",
      "227 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1961295 French words.\n",
      "355 unique French words.\n",
      "10 Most common words in the French dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "french_words_counter = collections.Counter([word for sentence in french_sentences for word in sentence.split()])\n",
    "\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words.'.format(len([word for sentence in french_sentences for word in sentence.split()])))\n",
    "print('{} unique French words.'.format(len(french_words_counter)))\n",
    "print('10 Most common words in the French dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786d069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e01ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "173bbbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(x):\n",
    "    \"\"\"\n",
    "    Tokenize x\n",
    "    :param x: List of sentences/strings to be tokenized\n",
    "    :return: Tuple of (tokenized x data, tokenizer used to tokenize x)\n",
    "    \"\"\"\n",
    "    # Create the tokeninzer\n",
    "    t = Tokenizer()\n",
    "    # Create dictionary mapping words (str) to their rank/index (int)\n",
    "    t.fit_on_texts(x)\n",
    "    # Use the tokenizer to tokenize the text\n",
    "    text_sequences = t.texts_to_sequences(x)\n",
    "    return text_sequences, t\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize Example output\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "338d5e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    \"\"\"\n",
    "    Pad x\n",
    "    :param x: List of sequences.\n",
    "    :param length: Length to pad the sequence to.  If None, use length of longest sequence in x.\n",
    "    :return: Padded numpy array of sequences\n",
    "    \"\"\"\n",
    "    # TODO: Implement\n",
    "    \n",
    "    # If length equals None, set it to be the length of the longest sequence in x\n",
    "    if length == None:\n",
    "        length = len(max(x, key=len))\n",
    "        \n",
    "    # Use Keras's pad_sequences to pad the sequences with 0's\n",
    "    padded_sequences = pad_sequences(sequences=x, maxlen=length, padding='post', value=0)\n",
    "    \n",
    "    return padded_sequences\n",
    "\n",
    "\n",
    "\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1773b721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 15\n",
      "Max French sentence length: 21\n",
      "English vocabulary size: 199\n",
      "French vocabulary size: 344\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"\n",
    "    Preprocess x and y\n",
    "    :param x: Feature List of sentences\n",
    "    :param y: Label List of sentences\n",
    "    :return: Tuple of (Preprocessed x, Preprocessed y, x tokenizer, y tokenizer)\n",
    "    \"\"\"\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "\n",
    "preproc_english_sentences, preproc_french_sentences, english_tokenizer, french_tokenizer =\\\n",
    "    preprocess(english_sentences, french_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_french_sequence_length = preproc_french_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "french_vocab_size = len(french_tokenizer.word_index)\n",
    "\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max French sentence length:\", max_french_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"French vocabulary size:\", french_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a736e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "english_sentences_train, english_sentences_test, french_sentences_train, french_sentences_test =\\\n",
    "    train_test_split(english_sentences, french_sentences, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a1e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1458806 English words in the training set.\n",
      "227 unique English words in the training set.\n",
      "10 Most common words in the English training dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "1568964 French words in the training set.\n",
      "354 unique French words in the training set.\n",
      "10 Most common words in the French training dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "# Calculate the training set stats\n",
    "\n",
    "english_train_words_counter = collections.Counter([word for sentence in english_sentences_train for word in sentence.split()])\n",
    "french_train_words_counter = collections.Counter([word for sentence in french_sentences_train for word in sentence.split()])\n",
    "\n",
    "print('{} English words in the training set.'.format(len([word for sentence in english_sentences_train for word in sentence.split()])))\n",
    "print('{} unique English words in the training set.'.format(len(english_train_words_counter)))\n",
    "print('10 Most common words in the English training dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_train_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words in the training set.'.format(len([word for sentence in french_sentences_train for word in sentence.split()])))\n",
    "print('{} unique French words in the training set.'.format(len(french_train_words_counter)))\n",
    "print('10 Most common words in the French training dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_train_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f5c1948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364444 English words in the test set.\n",
      "227 unique English words in the test set.\n",
      "10 Most common words in the English test dataset:\n",
      "\"is\" \",\" \".\" \"in\" \"it\" \"during\" \"the\" \"but\" \"and\" \"sometimes\"\n",
      "\n",
      "392331 French words in the test set.\n",
      "338 unique French words in the test set.\n",
      "10 Most common words in the French test dataset:\n",
      "\"est\" \".\" \",\" \"en\" \"il\" \"les\" \"mais\" \"et\" \"la\" \"parfois\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the test set stats\n",
    "\n",
    "english_test_words_counter = collections.Counter([word for sentence in english_sentences_test for word in sentence.split()])\n",
    "french_test_words_counter = collections.Counter([word for sentence in french_sentences_test for word in sentence.split()])\n",
    "\n",
    "print('{} English words in the test set.'.format(len([word for sentence in english_sentences_test for word in sentence.split()])))\n",
    "print('{} unique English words in the test set.'.format(len(english_test_words_counter)))\n",
    "print('10 Most common words in the English test dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_test_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} French words in the test set.'.format(len([word for sentence in french_sentences_test for word in sentence.split()])))\n",
    "print('{} unique French words in the test set.'.format(len(french_test_words_counter)))\n",
    "print('10 Most common words in the French test dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*french_test_words_counter.most_common(10)))[0]) + '\"')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d908a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Preprocessed\n",
      "Max English train dataset sentence length: 15\n",
      "Max French train dataset sentence length: 21\n",
      "English train dataset vocabulary size: 199\n",
      "French train dataset vocabulary size: 343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess the training split of the data\n",
    "\n",
    "preproc_english_sentences_train, preproc_french_sentences_train, english_tokenizer_train, french_tokenizer_train =\\\n",
    "    preprocess(english_sentences_train, french_sentences_train)\n",
    "    \n",
    "max_english_sequence_length_train = preproc_english_sentences_train.shape[1]\n",
    "max_french_sequence_length_train = preproc_french_sentences_train.shape[1]\n",
    "english_vocab_size_train = len(english_tokenizer_train.word_index)\n",
    "french_vocab_size_train = len(french_tokenizer_train.word_index)\n",
    "\n",
    "print('Training Data Preprocessed')\n",
    "print(\"Max English train dataset sentence length:\", max_english_sequence_length_train)\n",
    "print(\"Max French train dataset sentence length:\", max_french_sequence_length_train)\n",
    "print(\"English train dataset vocabulary size:\", english_vocab_size_train)\n",
    "print(\"French train dataset vocabulary size:\", french_vocab_size_train)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97f64bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data Preprocessed\n",
      "Max English test dataset sentence length: 15\n",
      "Max French test dataset sentence length: 20\n",
      "English test datset vocab size: 199\n",
      "French test dataset vocab size 326\n",
      "(27573, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess the test split of the data \n",
    "\n",
    "preproc_english_sentences_test, preproc_french_sentences_test, english_tokenizer_test, french_tokenizer_test =\\\n",
    "    preprocess(english_sentences_test, french_sentences_test)\n",
    "    \n",
    "max_english_sequence_length_test = preproc_english_sentences_test.shape[1]\n",
    "max_french_sequence_length_test = preproc_french_sentences_test.shape[1]\n",
    "english_vocab_size_test = len(english_tokenizer_test.word_index)\n",
    "french_vocab_size_test = len(french_tokenizer_test.word_index)\n",
    "\n",
    "print('Test Data Preprocessed')\n",
    "print('Max English test dataset sentence length:', max_english_sequence_length_test)\n",
    "print('Max French test dataset sentence length:', max_french_sequence_length_test)\n",
    "print('English test datset vocab size:', english_vocab_size_test)\n",
    "print('French test dataset vocab size', french_vocab_size_test)\n",
    "print(preproc_french_sentences_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "435def10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    \"\"\"\n",
    "    Turn logits from a neural network into text using the tokenizer\n",
    "    :param logits: Logits from a neural network\n",
    "    :param tokenizer: Keras Tokenizer fit on the labels\n",
    "    :return: String that represents the text of the logits\n",
    "    \"\"\"\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = ''\n",
    "\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "\n",
    "print('`logits_to_text` function loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6fc16e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encdec_model_train(input_shape, output_sequence_length, english_vocab_size, french_vocab_size):\n",
    "    \"\"\"\n",
    "    Build and train an encoder-decoder model on x and y\n",
    "    :param input_shape: Tuple of input shape\n",
    "    :param output_sequence_length: Length of output sequence\n",
    "    :param english_vocab_size: Number of unique English words in the dataset\n",
    "    :param french_vocab_size: Number of unique French words in the dataset\n",
    "    :return: Keras model built, but not trained\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build the encoder-decoder RNN model\n",
    "    input_layer= Input(shape=input_shape[1:])\n",
    "    encoder = Bidirectional(GRU(256, recurrent_dropout=0.2))(input_layer)\n",
    "    repeat_vector = RepeatVector(output_sequence_length)(encoder)\n",
    "    decoder = Bidirectional(GRU(256, return_sequences=True, recurrent_dropout=0.2))(repeat_vector)\n",
    "    dense_layer = Dense(french_vocab_size, activation='relu')(decoder)\n",
    "    output_layer = TimeDistributed(Dense(french_vocab_size, activation='softmax'))(decoder)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    # Compile the model\n",
    "    learning_rate = 0.01\n",
    "    model.compile(loss=sparse_categorical_crossentropy,\n",
    "                  optimizer=Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6395f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience = 5,  verbose=1)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9b0093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47023f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "813bfa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhruv Jain\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 460s 1s/step - loss: 1.6509 - accuracy: 0.5754 - val_loss: 1.3039 - val_accuracy: 0.6237\n",
      "Epoch 2/2\n",
      "442/442 [==============================] - 431s 975ms/step - loss: 1.2367 - accuracy: 0.6366 - val_loss: 1.1411 - val_accuracy: 0.6631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d5d5e61300>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape the input\n",
    "# with tf.device(\"CPU\"):\n",
    "tmp_x = pad(preproc_english_sentences_train, max_french_sequence_length_train)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_french_sentences_train.shape[-2], 1))\n",
    "\n",
    "# Train the model\n",
    "encoder_decoder_model_train = encdec_model_train(tmp_x.shape,\n",
    "                                     max_french_sequence_length_train,\n",
    "                                     english_vocab_size_train + 1,\n",
    "                                     french_vocab_size_train + 1)\n",
    "encoder_decoder_model_train.fit(tmp_x, preproc_french_sentences_train, callbacks=[es], batch_size=200, epochs=2, validation_split=0.2)\n",
    "\n",
    "# # Print the prediction(s)\n",
    "# print(logits_to_text(encoder_decoder_model_train.predict(tmp_x[:5])[0], french_tokenizer_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a85ace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ea27f75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110288, 21, 1)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pad(preproc_english_sentences_test, max_french_sequence_length_test)\n",
    "preproc_english_sentences_test.shape\n",
    "preproc_french_sentences_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "29d7ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27573, 21, 1)\n",
      "(110288, 21, 1)\n",
      "(27573, 21, 1)\n",
      "Encoder-decoder model accuracy on the unseen test data: 58.04%\n"
     ]
    }
   ],
   "source": [
    "test_x = pad(preproc_english_sentences_test, max_french_sequence_length_train)\n",
    "test_x = test_x.reshape((-1, max_french_sequence_length_train, 1))\n",
    "preproc_french_sentences_test = pad(preproc_french_sentences_test, max_french_sequence_length_train)  # Pad preproc_french_sentences_test\n",
    "preproc_french_sentences_test = preproc_french_sentences_test.reshape((-1, max_french_sequence_length_train, 1))  # Reshape using max_french_sequence_length_train\n",
    "\n",
    "print(test_x.shape)\n",
    "print(preproc_french_sentences_train.shape)\n",
    "print(preproc_french_sentences_test.shape)\n",
    "\n",
    "# Evaluate the model\n",
    "encoder_decoder_model_score = encoder_decoder_model_train.evaluate(test_x, preproc_french_sentences_test, verbose=0)\n",
    "\n",
    "print(\"Encoder-decoder model accuracy on the unseen test data: {0:.2f}%\".format(encoder_decoder_model_score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0bd3408b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 819ms/step\n",
      "nous détestons les oranges les les et les             \n",
      "\n",
      "\n",
      "ils aiment les pommes , les oranges et les poires .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(logits_to_text(encoder_decoder_model_train.predict(test_x[:4])[3], french_tokenizer_train))\n",
    "print('\\n')\n",
    "print(french_sentences_test[:4][3])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4738cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "encoder_decoder_model_train.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cba1b272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "29",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m predicted_sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m predicted_indices:\n\u001b[1;32m---> 12\u001b[0m     predicted_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([french_tokenizer\u001b[38;5;241m.\u001b[39mword_index[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Exclude padding and start-of-sequence tokens\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     predicted_sentences\u001b[38;5;241m.\u001b[39mappend(predicted_sentence)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert target sentences from one-hot encoded vectors to integer indices\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[98], line 12\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     10\u001b[0m predicted_sentences \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m predicted_indices:\n\u001b[1;32m---> 12\u001b[0m     predicted_sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43mfrench_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_index\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m indices \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m])  \u001b[38;5;66;03m# Exclude padding and start-of-sequence tokens\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     predicted_sentences\u001b[38;5;241m.\u001b[39mappend(predicted_sentence)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Convert target sentences from one-hot encoded vectors to integer indices\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 29"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "# Generate predictions using the encoder-decoder model\n",
    "predictions = encoder_decoder_model_train.predict(test_x[:10])\n",
    "\n",
    "# Convert predictions from one-hot encoded vectors to integer indices\n",
    "predicted_indices = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Convert integer indices to words\n",
    "predicted_sentences = []\n",
    "for indices in predicted_indices:\n",
    "    predicted_sentence = ' '.join([french_tokenizer.word_index[i] for i in indices if i > 0])  # Exclude padding and start-of-sequence tokens\n",
    "    predicted_sentences.append(predicted_sentence)\n",
    "\n",
    "# Convert target sentences from one-hot encoded vectors to integer indices\n",
    "target_indices = np.argmax(preproc_french_sentences_test, axis=2)\n",
    "\n",
    "# Convert integer indices to words\n",
    "target_sentences = []\n",
    "for indices in target_indices:\n",
    "    target_sentence = ' '.join([french_tokenizer[i] for i in indices if i > 0])  # Exclude padding and start-of-sequence tokens\n",
    "    target_sentences.append(target_sentence)\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = corpus_bleu([[sent] for sent in target_sentences], predicted_sentences)\n",
    "print(\"BLEU score: {0:.4f}\".format(bleu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45a1652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51317965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
